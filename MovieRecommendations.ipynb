{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Agente Recomendador de Pel√≠culas y Series\n",
    "\n",
    "Sistema de recomendaciones basado en Agentic RAG con ~20k pel√≠culas y series.\n",
    "\n",
    "**Stack:**\n",
    "- LLM: Llama 3.1 8B (HuggingFace)\n",
    "- Vector Store: Pinecone\n",
    "- Framework: LangChain + LangGraph\n",
    "- Interfaz: Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Instalaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pinecone 7.3.0\n",
      "Uninstalling pinecone-7.3.0:\n",
      "  Successfully uninstalled pinecone-7.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pinecone-client as it is not installed.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-pinecone 0.2.13 requires pinecone[asyncio]<8.0.0,>=6.0.0, which is not installed.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.18 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.2 which is incompatible.\n",
      "langchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.18 which is incompatible.\n",
      "langchain-huggingface 1.2.0 requires langchain-core<2.0.0,>=1.2.0, but you have langchain-core 0.3.18 which is incompatible.\n",
      "langchain-openai 1.1.4 requires langchain-core<2.0.0,>=1.2.1, but you have langchain-core 0.3.18 which is incompatible.\n",
      "langchain-pinecone 0.2.13 requires langchain-core<2.0.0,>=0.3.34, but you have langchain-core 0.3.18 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.7 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 1.2.3 which is incompatible.\n",
      "langchain 0.3.7 requires langchain-text-splitters<0.4.0,>=0.3.0, but you have langchain-text-splitters 1.1.0 which is incompatible.\n",
      "langchain 0.3.7 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.5.0 which is incompatible.\n",
      "langgraph 0.2.19 requires langchain-core<0.4,>=0.2.38, but you have langchain-core 1.2.3 which is incompatible.\n",
      "langgraph-checkpoint 1.0.12 requires langchain-core<0.4,>=0.2.38, but you have langchain-core 1.2.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Ignored the following yanked versions: 2.2.0, 2.2.5\n",
      "ERROR: Could not find a version that satisfies the requirement pinecone-client<8.0.0,>=7.0.0 (from versions: 0.7.5, 0.7.11, 0.7.13, 0.7.16, 0.7.17, 0.7.26, 0.7.27, 0.7.42, 0.7.44, 0.7.46, 0.8.1, 0.8.5, 0.8.7, 0.8.8, 0.8.9, 0.8.10, 0.8.27, 0.8.33, 0.8.34, 0.8.36, 0.8.37, 0.8.38, 0.8.39b0, 0.8.39rc0, 0.8.39, 0.8.53, 0.8.56, 0.8.58, 0.8.59, 0.8.60, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10, 2.0.11, 2.0.12, 2.0.13, 2.1.0, 2.2.1, 2.2.2rc1, 2.2.2rc3, 2.2.2rc4, 2.2.2, 2.2.3rc1, 2.2.3, 2.2.4, 2.2.5rc2, 2.3.0.dev1, 3.0.0.dev1, 3.0.0.dev2, 3.0.0.dev3, 3.0.0.dev4, 3.0.0.dev5, 3.0.0.dev6, 3.0.0.dev7, 3.0.0.dev8, 3.0.0.dev9, 3.0.0.dev10, 3.0.0rc2, 3.0.0rc3, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0.dev1, 3.1.0, 3.2.0, 3.2.1, 3.2.2, 4.0.0, 4.1.0, 4.1.1, 4.1.2, 5.0.0, 5.0.1, 6.0.0.dev3, 6.0.0)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pinecone-client<8.0.0,>=7.0.0\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pinecone-client pinecone\n",
    "!pip install -q langchain==0.3.7 langchain-core==0.3.18 langgraph==0.2.19\n",
    "!pip install -q langchain-community langchain-pinecone langchain-huggingface\n",
    "!pip install -q sentence-transformers \"pinecone-client>=7.0.0,<8.0.0\"\n",
    "!pip install -q huggingface-hub transformers torch\n",
    "!pip install -q gradio pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports b√°sicos cargados\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Optional, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imports b√°sicos cargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga de Datasets\n",
    "\n",
    "Cargaremos 3 datasets:\n",
    "- IMDB Top 1000: 1,000 pel√≠culas cl√°sicas\n",
    "- IMDB Films/TV: 11,414 registros mixtos\n",
    "- Netflix: 7,789 pel√≠culas + series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Top 1000: 1,000 registros\n",
      "IMDB Films/TV: 11,414 registros\n",
      "Netflix: 7,787 registros\n",
      "\n",
      " Total antes de unificar: 20,201 registros\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets\n",
    "df_imdb_top = pd.read_csv('Datasets/imdb_top_1000.csv')\n",
    "df_imdb_films = pd.read_csv('Datasets/imdb Tv Series and Films.csv')\n",
    "df_netflix = pd.read_csv('Datasets/NetFlix.csv')\n",
    "\n",
    "print(f\"IMDB Top 1000: {len(df_imdb_top):,} registros\")\n",
    "print(f\"IMDB Films/TV: {len(df_imdb_films):,} registros\")\n",
    "print(f\"Netflix: {len(df_netflix):,} registros\")\n",
    "print(f\"\\n Total antes de unificar: {len(df_imdb_top) + len(df_imdb_films) + len(df_netflix):,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funciones de Limpieza de Datos\n",
    "\n",
    "Estas funciones normalizar√°n y limpiar√°n los datos de los 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de limpieza definidas\n"
     ]
    }
   ],
   "source": [
    "def detect_type_from_year(year_str):\n",
    "    \"\"\"\n",
    "    Detecta si es Movie o TV Show bas√°ndose en el formato del a√±o.\n",
    "    TV shows: \"2018‚Äì2023\" o \"2023‚Äì\" (en curso)\n",
    "    Movies: \"2023\"\n",
    "    \"\"\"\n",
    "    if pd.isna(year_str):\n",
    "        return \"Movie\"  # Default\n",
    "    \n",
    "    year_str = str(year_str).strip()\n",
    "    \n",
    "    # TV shows tienen rangos con guiones\n",
    "    if '‚Äì' in year_str or '‚Äî' in year_str or '-' in year_str:\n",
    "        return \"TV Show\"\n",
    "    \n",
    "    return \"Movie\"\n",
    "\n",
    "\n",
    "def extract_year_start(year_str):\n",
    "    \"\"\"\n",
    "    Extrae el a√±o de inicio de '2018‚Äì2023' o '2023'\n",
    "    \"\"\"\n",
    "    if pd.isna(year_str):\n",
    "        return 0\n",
    "    \n",
    "    year_str = str(year_str).strip()\n",
    "    \n",
    "    # Normalizar guiones\n",
    "    year_str = year_str.replace('‚Äì', '-').replace('‚Äî', '-')\n",
    "    \n",
    "    # Quitar espacios y guiones finales\n",
    "    year_str = year_str.replace('- ', f'-{datetime.now().year}')\n",
    "    \n",
    "    # Split y tomar primer a√±o\n",
    "    parts = year_str.split('-')\n",
    "    \n",
    "    try:\n",
    "        return int(parts[0])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def extract_year_end(year_str):\n",
    "    \"\"\"\n",
    "    Extrae el a√±o final, o a√±o de inicio si es single year.\n",
    "    Para series en curso (\"2023‚Äì\"), usa a√±o actual.\n",
    "    \"\"\"\n",
    "    if pd.isna(year_str):\n",
    "        return 0\n",
    "    \n",
    "    year_str = str(year_str).strip()\n",
    "    \n",
    "    # Normalizar guiones\n",
    "    year_str = year_str.replace('‚Äì', '-').replace('‚Äî', '-')\n",
    "    \n",
    "    year_str = year_str.replace('- ', f'-{datetime.now().year}')\n",
    "    year_str = year_str.replace('-\\s*$', f'-{datetime.now().year}')\n",
    "    \n",
    "    parts = year_str.split('-')\n",
    "    \n",
    "    try:\n",
    "        if len(parts) > 1:\n",
    "            return int(parts[1]) if parts[1].strip() else datetime.now().year\n",
    "        return int(parts[0])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def clean_cast_field(cast_str, field_type):\n",
    "    \"\"\"\n",
    "    Extrae Director o Stars del formato messy de IMDB Films:\n",
    "    'Directors:, Name, | , Stars:, Name1, , Name2, ,'\n",
    "    \n",
    "    Args:\n",
    "        cast_str: String con formato IMDB\n",
    "        field_type: 'Director' o 'Stars'\n",
    "    \"\"\"\n",
    "    if pd.isna(cast_str):\n",
    "        return \"N/A\"\n",
    "    \n",
    "    cast_str = str(cast_str)\n",
    "    \n",
    "    if field_type == 'Director':\n",
    "        # Buscar entre \"Director(s):\" y \"|\"\n",
    "        if 'Director' in cast_str:\n",
    "            match = re.search(r'Directors?:,?\\s*([^,|]+)', cast_str)\n",
    "            if match:\n",
    "                director = match.group(1).strip()\n",
    "                # Limpiar residuos\n",
    "                director = director.replace('|', '').strip()\n",
    "                return director if director else \"N/A\"\n",
    "        return \"N/A\"\n",
    "    \n",
    "    elif field_type == 'Stars':\n",
    "        # Extraer despu√©s de \"Stars:\"\n",
    "        if 'Stars:' in cast_str:\n",
    "            stars_part = cast_str.split('Stars:')[1]\n",
    "            # Limpiar comas extras y espacios\n",
    "            stars = [s.strip() for s in stars_part.split(',') if s.strip() and s.strip() != '|']\n",
    "            # Tomar top 4\n",
    "            return ', '.join(stars[:4]) if stars else \"N/A\"\n",
    "        return \"N/A\"\n",
    "    \n",
    "    return \"N/A\"\n",
    "\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Parse '140 min' ‚Üí 140\n",
    "    \"\"\"\n",
    "    if pd.isna(duration_str):\n",
    "        return 0\n",
    "    \n",
    "    duration_str = str(duration_str).strip()\n",
    "    match = re.search(r'(\\d+)', duration_str)\n",
    "    \n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "def parse_netflix_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Parse Netflix duration:\n",
    "    - '4 Seasons' ‚Üí 240 (4 * 60)\n",
    "    - '143 min' ‚Üí 143\n",
    "    \"\"\"\n",
    "    if pd.isna(duration_str):\n",
    "        return 0\n",
    "    \n",
    "    duration_str = str(duration_str).strip()\n",
    "    \n",
    "    if 'Season' in duration_str:\n",
    "        # Estimar: 1 season ‚âà 60 min promedio\n",
    "        match = re.search(r'(\\d+)', duration_str)\n",
    "        seasons = int(match.group(1)) if match else 1\n",
    "        return seasons * 60\n",
    "    else:\n",
    "        match = re.search(r'(\\d+)', duration_str)\n",
    "        return int(match.group(1)) if match else 0\n",
    "\n",
    "\n",
    "def convert_rating_to_numeric(rating_str):\n",
    "    \"\"\"\n",
    "    Convierte ratings a escala num√©rica 0-10:\n",
    "    - Ratings num√©ricos (IMDB): pasar directo\n",
    "    - TV-MA, R: ~7.0\n",
    "    - PG-13: ~6.5\n",
    "    - PG, TV-PG: ~6.0\n",
    "    - G, TV-G: ~5.5\n",
    "    \"\"\"\n",
    "    if pd.isna(rating_str):\n",
    "        return 0.0\n",
    "    \n",
    "    rating_str = str(rating_str).strip()\n",
    "    \n",
    "    # Intentar num√©rico primero\n",
    "    try:\n",
    "        return float(rating_str)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Mapeo de certificados ‚Üí ratings estimados\n",
    "    rating_map = {\n",
    "        'TV-MA': 7.0, 'R': 7.0, 'NC-17': 7.5,\n",
    "        'TV-14': 6.5, 'PG-13': 6.5,\n",
    "        'TV-PG': 6.0, 'PG': 6.0,\n",
    "        'TV-G': 5.5, 'G': 5.5, 'TV-Y': 5.5,\n",
    "        'NR': 0.0, 'UR': 0.0, 'N/A': 0.0,\n",
    "        'A': 7.0, 'UA': 6.5, 'U': 6.0,  # Indian ratings\n",
    "        'Passed': 6.0, 'Approved': 6.0\n",
    "    }\n",
    "    \n",
    "    return rating_map.get(rating_str, 0.0)\n",
    "\n",
    "\n",
    "def normalize_genres(genres_str):\n",
    "    \"\"\"\n",
    "    Normaliza g√©neros entre datasets:\n",
    "    - Remueve prefijos \"TV Shows\", \"Movies\", \"International\"\n",
    "    - Estandariza: \"Sci-Fi\" ‚Üí \"Science Fiction\"\n",
    "    - Retorna top 3 g√©neros\n",
    "    \"\"\"\n",
    "    if pd.isna(genres_str):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Remover prefijos de Netflix\n",
    "    genres_str = str(genres_str)\n",
    "    genres_str = genres_str.replace('Movies', '').replace('TV Shows', '')\n",
    "    genres_str = genres_str.replace('International', '').replace('British', '')\n",
    "    \n",
    "    genres = [g.strip() for g in genres_str.split(',') if g.strip()]\n",
    "    \n",
    "    # Estandarizar variaciones\n",
    "    genre_map = {\n",
    "        'Sci-Fi': 'Science Fiction',\n",
    "        'Romantic': 'Romance',\n",
    "        'Comedies': 'Comedy',\n",
    "        'Thrillers': 'Thriller',\n",
    "        'Dramas': 'Drama',\n",
    "        'Documentaries': 'Documentary',\n",
    "        'Kids': 'Family',\n",
    "        \"Children's\": 'Family'\n",
    "    }\n",
    "    \n",
    "    normalized = []\n",
    "    for g in genres[:3]: \n",
    "        g_clean = g.replace('TV', '').strip()\n",
    "        normalized.append(genre_map.get(g_clean, g_clean))\n",
    "    \n",
    "    return ', '.join(normalized) if normalized else \"Unknown\"\n",
    "\n",
    "\n",
    "print(\"Funciones de limpieza definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unificaci√≥n de IMDB Top 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando IMDB Top 1000...\n",
      "IMDB Top 1000 unificado: 1,000 registros\n"
     ]
    }
   ],
   "source": [
    "unified_imdb_top = []\n",
    "\n",
    "print(\"Procesando IMDB Top 1000...\")\n",
    "\n",
    "for idx, row in df_imdb_top.iterrows():\n",
    "      try:\n",
    "          try:\n",
    "              year_val = int(row['Released_Year'])\n",
    "          except:\n",
    "              year_val = 0\n",
    "\n",
    "          votes_val = 0\n",
    "          if pd.notna(row['No_of_Votes']):\n",
    "              votes_str = str(row['No_of_Votes']).replace(',', '')\n",
    "              try:\n",
    "                  votes_val = int(votes_str)\n",
    "              except:\n",
    "                  votes_val = 0\n",
    "\n",
    "          # Manejar rating\n",
    "          try:\n",
    "              rating_val = float(row['IMDB_Rating'])\n",
    "          except:\n",
    "              rating_val = 0.0\n",
    "\n",
    "          record = {\n",
    "              'content_id': f\"imdb_top_{idx:04d}\",\n",
    "              'source': 'imdb_top_1000',\n",
    "              'title': row['Series_Title'],\n",
    "              'type': 'Movie',\n",
    "              'year': str(year_val) if year_val > 0 else 'N/A',\n",
    "              'year_start': year_val,\n",
    "              'year_end': year_val,\n",
    "              'genres': normalize_genres(row['Genre']),\n",
    "              'rating': str(row['IMDB_Rating']),\n",
    "              'rating_numeric': rating_val,\n",
    "              'duration': row['Runtime'],\n",
    "              'duration_minutes': parse_duration(row['Runtime']),\n",
    "              'description': row['Overview'] if pd.notna(row['Overview']) else 'N/A',\n",
    "              'director': row['Director'] if pd.notna(row['Director']) else 'N/A',\n",
    "              'cast': f\"{row['Star1']}, {row['Star2']}, {row['Star3']}, {row['Star4']}\",\n",
    "              'country': 'N/A',\n",
    "              'certificate': row['Certificate'] if pd.notna(row['Certificate']) else 'N/A',\n",
    "              'votes': votes_val\n",
    "          }\n",
    "          unified_imdb_top.append(record)\n",
    "      except Exception as e:\n",
    "          print(f\"Error en fila {idx}: {e}\")\n",
    "          continue\n",
    "\n",
    "df_unified_imdb_top = pd.DataFrame(unified_imdb_top)\n",
    "print(f\"IMDB Top 1000 unificado: {len(df_unified_imdb_top):,} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Unificaci√≥n de IMDB Films/TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando IMDB Films/TV...\n",
      "   Procesados 1,000/11,414...\n",
      "   Procesados 2,000/11,414...\n",
      "   Procesados 3,000/11,414...\n",
      "   Procesados 4,000/11,414...\n",
      "   Procesados 5,000/11,414...\n",
      "   Procesados 6,000/11,414...\n",
      "   Procesados 7,000/11,414...\n",
      "   Procesados 8,000/11,414...\n",
      "   Procesados 9,000/11,414...\n",
      "   Procesados 10,000/11,414...\n",
      "   Procesados 11,000/11,414...\n",
      "IMDB Films/TV unificado: 11,414 registros\n"
     ]
    }
   ],
   "source": [
    "unified_imdb_films = []\n",
    "\n",
    "print(\"Procesando IMDB Films/TV...\")\n",
    "\n",
    "for idx, row in df_imdb_films.iterrows():\n",
    "      if (idx + 1) % 1000 == 0:\n",
    "          print(f\"   Procesados {idx + 1:,}/{len(df_imdb_films):,}...\")\n",
    "\n",
    "      try:\n",
    "          record = {\n",
    "              'content_id': row['IMDb ID'] if pd.notna(row['IMDb ID']) else f\"imdb_films_{idx:05d}\",\n",
    "              'source': 'imdb_films',\n",
    "              'title': row['Title'],\n",
    "              'type': detect_type_from_year(row['Release Year']),\n",
    "              'year': str(row['Release Year']),\n",
    "              'year_start': extract_year_start(row['Release Year']),\n",
    "              'year_end': extract_year_end(row['Release Year']),\n",
    "              'genres': normalize_genres(row['Genre']),\n",
    "              'rating': str(row['Rating']) if pd.notna(row['Rating']) else 'N/A',\n",
    "              'rating_numeric': float(row['Rating']) if pd.notna(row['Rating']) else 0.0,\n",
    "              'duration': row['Runtime'] if pd.notna(row['Runtime']) else 'N/A',\n",
    "              'duration_minutes': parse_duration(row['Runtime']),\n",
    "              'description': row['Synopsis'] if pd.notna(row['Synopsis']) else 'N/A',\n",
    "              'director': clean_cast_field(row['Cast'], 'Director'),\n",
    "              'cast': clean_cast_field(row['Cast'], 'Stars'),\n",
    "              'country': 'N/A',\n",
    "              'certificate': row['Certificate'] if pd.notna(row['Certificate']) else 'N/A',\n",
    "              'votes': int(row['Number of Votes']) if pd.notna(row['Number of Votes']) else 0\n",
    "          }\n",
    "          unified_imdb_films.append(record)\n",
    "      except Exception as e:\n",
    "          print(f\"Error en fila {idx}: {e}\")\n",
    "          continue\n",
    "\n",
    "df_unified_imdb_films = pd.DataFrame(unified_imdb_films)\n",
    "print(f\"IMDB Films/TV unificado: {len(df_unified_imdb_films):,} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Unificaci√≥n de Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Netflix...\n",
      "   Procesados 1,000/7,787...\n",
      "   Procesados 2,000/7,787...\n",
      "   Procesados 3,000/7,787...\n",
      "   Procesados 4,000/7,787...\n",
      "   Procesados 5,000/7,787...\n",
      "   Procesados 6,000/7,787...\n",
      "   Procesados 7,000/7,787...\n",
      "Netflix unificado: 7,787 registros\n"
     ]
    }
   ],
   "source": [
    "unified_netflix = []\n",
    "\n",
    "print(\"Procesando Netflix...\")\n",
    "\n",
    "for idx, row in df_netflix.iterrows():\n",
    "      if (idx + 1) % 1000 == 0:\n",
    "          print(f\"   Procesados {idx + 1:,}/{len(df_netflix):,}...\")\n",
    "\n",
    "      try:\n",
    "          record = {\n",
    "              'content_id': row['show_id'],\n",
    "              'source': 'netflix',\n",
    "              'title': row['title'],\n",
    "              'type': row['type'],\n",
    "              'year': str(row['release_year']),\n",
    "              'year_start': int(row['release_year']),\n",
    "              'year_end': int(row['release_year']),\n",
    "              'genres': normalize_genres(row['genres']),\n",
    "              'rating': row['rating'] if pd.notna(row['rating']) else 'N/A',\n",
    "              'rating_numeric': convert_rating_to_numeric(row['rating']),\n",
    "              'duration': row['duration'] if pd.notna(row['duration']) else 'N/A',\n",
    "              'duration_minutes': parse_netflix_duration(row['duration']),\n",
    "              'description': row['description'] if pd.notna(row['description']) else 'N/A',\n",
    "              'director': row['director'] if pd.notna(row['director']) else 'N/A',\n",
    "              'cast': row['cast'] if pd.notna(row['cast']) else 'N/A',\n",
    "              'country': row['country'] if pd.notna(row['country']) else 'N/A',\n",
    "              'certificate': row['rating'] if pd.notna(row['rating']) else 'N/A',\n",
    "              'votes': 0\n",
    "          }\n",
    "          unified_netflix.append(record)\n",
    "      except Exception as e:\n",
    "          print(f\"Error en fila {idx}: {e}\")\n",
    "          continue\n",
    "\n",
    "df_unified_netflix = pd.DataFrame(unified_netflix)\n",
    "print(f\"Netflix unificado: {len(df_unified_netflix):,} registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Merge y Deduplicaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total antes de deduplicaci√≥n: 20,201 registros\n",
      "   - IMDB Top: 1,000\n",
      "   - IMDB Films: 11,414\n",
      "   - Netflix: 7,787\n"
     ]
    }
   ],
   "source": [
    "# Concatenar todos los DataFrames\n",
    "df_all = pd.concat([df_unified_imdb_top, df_unified_imdb_films, df_unified_netflix], ignore_index=True)\n",
    "\n",
    "print(f\" Total antes de deduplicaci√≥n: {len(df_all):,} registros\")\n",
    "print(f\"   - IMDB Top: {len(df_unified_imdb_top):,}\")\n",
    "print(f\"   - IMDB Films: {len(df_unified_imdb_films):,}\")\n",
    "print(f\"   - Netflix: {len(df_unified_netflix):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Deduplicando registros...\n",
      "    Duplicados removidos: 2,857\n",
      "    Registros finales: 17,344\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_records(unified_df):\n",
    "    \"\"\"\n",
    "    Remueve duplicados priorizando:\n",
    "    1. IMDB IDs (m√°s autoritativo)\n",
    "    2. Mayor cantidad de votes\n",
    "    3. Metadata m√°s completa\n",
    "    \"\"\"\n",
    "    print(\"\\n Deduplicando registros...\")\n",
    "    \n",
    "    # Crear clave de deduplicaci√≥n\n",
    "    unified_df['dedup_key'] = (\n",
    "        unified_df['title'].str.lower().str.strip() + '_' + \n",
    "        unified_df['year_start'].astype(str) + '_' + \n",
    "        unified_df['type']\n",
    "    )\n",
    "    \n",
    "    # Funci√≥n de scoring (mayor = mejor)\n",
    "    def score_record(row):\n",
    "        score = 0\n",
    "        \n",
    "        # IMDB ID = m√°s confiable\n",
    "        if row['content_id'].startswith('tt'):\n",
    "            score += 100\n",
    "        \n",
    "        # Votes = popularidad\n",
    "        score += min(row['votes'] / 1000, 50)\n",
    "        \n",
    "        # Descripci√≥n completa\n",
    "        if row['description'] != 'N/A' and len(row['description']) > 50:\n",
    "            score += 20\n",
    "        \n",
    "        # Director disponible\n",
    "        if row['director'] != 'N/A':\n",
    "            score += 10\n",
    "        \n",
    "        # Cast disponible\n",
    "        if row['cast'] != 'N/A':\n",
    "            score += 10\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    unified_df['quality_score'] = unified_df.apply(score_record, axis=1)\n",
    "    \n",
    "    # Ordenar por score y quedarse con el mejor de cada grupo\n",
    "    deduplicated = unified_df.sort_values('quality_score', ascending=False).drop_duplicates(\n",
    "        subset=['dedup_key'], keep='first'\n",
    "    )\n",
    "    \n",
    "    duplicates_removed = len(unified_df) - len(deduplicated)\n",
    "    print(f\"    Duplicados removidos: {duplicates_removed:,}\")\n",
    "    print(f\"    Registros finales: {len(deduplicated):,}\")\n",
    "    \n",
    "    # Limpiar columnas temporales\n",
    "    deduplicated = deduplicated.drop(columns=['dedup_key', 'quality_score'])\n",
    "    \n",
    "    return deduplicated\n",
    "\n",
    "\n",
    "# Aplicar deduplicaci√≥n\n",
    "df_unified = deduplicate_records(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validaci√≥n de Calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " VALIDACI√ìN DE CALIDAD DEL DATASET UNIFICADO\n",
      "============================================================\n",
      "\n",
      " Registros totales: 17,344\n",
      "\n",
      " Por tipo:\n",
      "   - Pel√≠culas: 13,345\n",
      "   - Series: 3,999\n",
      "\n",
      " Calidad de descripciones:\n",
      "   - Con descripci√≥n: 17,344\n",
      "   - Sin descripci√≥n: 0\n",
      "\n",
      " Ratings:\n",
      "   - Rating promedio: 6.34/10\n",
      "   - Con rating > 0: 16,994\n",
      "\n",
      " Rango de a√±os:\n",
      "   - A√±o m√°s antiguo: 0\n",
      "   - A√±o m√°s reciente: 2025\n",
      "\n",
      " Top 10 g√©neros:\n",
      "   - Action, Crime, Drama: 1,017\n",
      "   - Animation, Action, Adventure: 899\n",
      "   - Drama: 649\n",
      "   - Action, Adventure, Drama: 593\n",
      "   - Action, Adventure, Comedy: 555\n",
      "   - Documentary: 506\n",
      "   - Action, Comedy, Crime: 390\n",
      "   - Comedy: 385\n",
      "   - Action, Crime, Thriller: 371\n",
      "   - Action, Adventure, Fantasy: 364\n",
      "\n",
      " Por fuente:\n",
      "   - imdb_films: 9,300\n",
      "   - netflix: 7,191\n",
      "   - imdb_top_1000: 853\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n VALIDACI√ìN DE CALIDAD DEL DATASET UNIFICADO\\n\" + \"=\"*60)\n",
    "\n",
    "print(f\"\\n Registros totales: {len(df_unified):,}\")\n",
    "print(f\"\\n Por tipo:\")\n",
    "print(f\"   - Pel√≠culas: {(df_unified['type'] == 'Movie').sum():,}\")\n",
    "print(f\"   - Series: {(df_unified['type'] == 'TV Show').sum():,}\")\n",
    "\n",
    "print(f\"\\n Calidad de descripciones:\")\n",
    "print(f\"   - Con descripci√≥n: {(df_unified['description'] != 'N/A').sum():,}\")\n",
    "print(f\"   - Sin descripci√≥n: {(df_unified['description'] == 'N/A').sum():,}\")\n",
    "\n",
    "print(f\"\\n Ratings:\")\n",
    "print(f\"   - Rating promedio: {df_unified['rating_numeric'].mean():.2f}/10\")\n",
    "print(f\"   - Con rating > 0: {(df_unified['rating_numeric'] > 0).sum():,}\")\n",
    "\n",
    "print(f\"\\n Rango de a√±os:\")\n",
    "print(f\"   - A√±o m√°s antiguo: {df_unified['year_start'].min()}\")\n",
    "print(f\"   - A√±o m√°s reciente: {df_unified['year_end'].max()}\")\n",
    "\n",
    "print(f\"\\n Top 10 g√©neros:\")\n",
    "for genre, count in df_unified['genres'].value_counts().head(10).items():\n",
    "    print(f\"   - {genre}: {count:,}\")\n",
    "\n",
    "print(f\"\\n Por fuente:\")\n",
    "for source, count in df_unified['source'].value_counts().items():\n",
    "    print(f\"   - {source}: {count:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Dataset Unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unificado guardado en: unified_dataset.csv\n",
      "Tama√±o del archivo: 6.02 MB\n",
      " 17,344 registros √ó 18 columnas\n"
     ]
    }
   ],
   "source": [
    "# Guardar a CSV\n",
    "output_file = 'unified_dataset.csv'\n",
    "df_unified.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset unificado guardado en: {output_file}\")\n",
    "print(f\"Tama√±o del archivo: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")\n",
    "print(f\" {len(df_unified):,} registros √ó {len(df_unified.columns)} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Preview de Registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ejemplo de pel√≠cula:\n",
      "   title: Spider-Man: Into the Spider-Verse\n",
      "   year: 2018\n",
      "   genres: Animation, Action, Adventure\n",
      "   rating_numeric: 8.4\n",
      "   description: Teen Miles Morales becomes the Spider-Man of his universe and must join with five spider-powered individuals from other dimensions to stop a threat for all realities.\n",
      "\n",
      " Ejemplo de serie:\n",
      "   title: Barry\n",
      "   year: 2018‚Äì2023\n",
      "   genres: Action, Comedy, Crime\n",
      "   rating_numeric: 8.4\n",
      "   description: A hit man from the Midwest moves to Los Angeles and gets caught up in the city's theatre arts scene.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>year_start</th>\n",
       "      <th>year_end</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_numeric</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>certificate</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11413</th>\n",
       "      <td>tt4633694</td>\n",
       "      <td>imdb_films</td>\n",
       "      <td>Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Animation, Action, Adventure</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>117 min</td>\n",
       "      <td>117</td>\n",
       "      <td>Teen Miles Morales becomes the Spider-Man of h...</td>\n",
       "      <td>Bob Persichetti</td>\n",
       "      <td>Shameik Moore, Jake Johnson, Hailee Steinfeld,...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>PG</td>\n",
       "      <td>575321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>tt1408101</td>\n",
       "      <td>imdb_films</td>\n",
       "      <td>Star Trek Into Darkness</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>132 min</td>\n",
       "      <td>132</td>\n",
       "      <td>After the crew of the Enterprise find an unsto...</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>Chris Pine, Zachary Quinto, Zoe Saldana, Bened...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>489502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>tt0401855</td>\n",
       "      <td>imdb_films</td>\n",
       "      <td>Underworld: Evolution</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>Action, Fantasy, Thriller</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>106 min</td>\n",
       "      <td>106</td>\n",
       "      <td>Picking up directly from the previous movie, v...</td>\n",
       "      <td>Len Wiseman</td>\n",
       "      <td>Kate Beckinsale, Scott Speedman, Bill Nighy, T...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>R</td>\n",
       "      <td>204681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      content_id      source                              title   type  year  \\\n",
       "11413  tt4633694  imdb_films  Spider-Man: Into the Spider-Verse  Movie  2018   \n",
       "1495   tt1408101  imdb_films            Star Trek Into Darkness  Movie  2013   \n",
       "2538   tt0401855  imdb_films              Underworld: Evolution  Movie  2006   \n",
       "\n",
       "       year_start  year_end                              genres rating  \\\n",
       "11413        2018      2018        Animation, Action, Adventure    8.4   \n",
       "1495         2013      2013  Action, Adventure, Science Fiction    7.7   \n",
       "2538         2006      2006           Action, Fantasy, Thriller    6.7   \n",
       "\n",
       "       rating_numeric duration  duration_minutes  \\\n",
       "11413             8.4  117 min               117   \n",
       "1495              7.7  132 min               132   \n",
       "2538              6.7  106 min               106   \n",
       "\n",
       "                                             description         director  \\\n",
       "11413  Teen Miles Morales becomes the Spider-Man of h...  Bob Persichetti   \n",
       "1495   After the crew of the Enterprise find an unsto...      J.J. Abrams   \n",
       "2538   Picking up directly from the previous movie, v...      Len Wiseman   \n",
       "\n",
       "                                                    cast country certificate  \\\n",
       "11413  Shameik Moore, Jake Johnson, Hailee Steinfeld,...     N/A          PG   \n",
       "1495   Chris Pine, Zachary Quinto, Zoe Saldana, Bened...     N/A       PG-13   \n",
       "2538   Kate Beckinsale, Scott Speedman, Bill Nighy, T...     N/A           R   \n",
       "\n",
       "        votes  \n",
       "11413  575321  \n",
       "1495   489502  \n",
       "2538   204681  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar algunos ejemplos\n",
    "print(\"\\n Ejemplo de pel√≠cula:\")\n",
    "movie_sample = df_unified[df_unified['type'] == 'Movie'].iloc[0]\n",
    "for col in ['title', 'year', 'genres', 'rating_numeric', 'description']:\n",
    "    print(f\"   {col}: {movie_sample[col]}\")\n",
    "\n",
    "print(\"\\n Ejemplo de serie:\")\n",
    "tv_sample = df_unified[df_unified['type'] == 'TV Show'].iloc[0]\n",
    "for col in ['title', 'year', 'genres', 'rating_numeric', 'description']:\n",
    "    print(f\"   {col}: {tv_sample[col]}\")\n",
    "\n",
    "df_unified.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FASE 1 COMPLETADA\n",
    "\n",
    "**Siguiente paso:** Esperar aprobaci√≥n de Llama 3.1 y continuar con:\n",
    "- Fase 2: Vector Store (Pinecone + Embeddings)\n",
    "- Fase 3: Tools del agente\n",
    "- Fase 4: StateGraph con LLM\n",
    "- Fase 5: Interfaz Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# FASE 2: Vector Store (Pinecone + Embeddings)\n",
    "\n",
    "Configuraremos Pinecone y subiremos los ~20k registros con embeddings para b√∫squeda sem√°ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencias de Fase 2 instaladas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\tatic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain-huggingface\n",
    "!pip install -q langchain-pinecone\n",
    "!pip install -q tqdm\n",
    "!pip install python-dotenv\n",
    "\n",
    "print(\"Dependencias de Fase 2 instaladas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Imports para RAG y Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports de LangChain y Pinecone cargados\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "import pinecone\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Imports de LangChain y Pinecone cargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Configuraci√≥n de API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndice 'movie-recommender' ya existe\n",
      "Pinecone configurado correctamente\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    " # API Keys\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "HUGGINGFACE_API_TOKEN = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "\n",
    "  # Configuraci√≥n del √≠ndice Pinecone\n",
    "PINECONE_INDEX_NAME = \"movie-recommender\"\n",
    "PINECONE_DIMENSION = 384\n",
    "NAMESPACE = \"movies-series\"\n",
    "\n",
    "print(\"Congiguraci√≥n Cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Inicializar Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de embeddings cargado\n",
      "Dimension: 384\n",
      "Primeros 5 valores: [-0.05855903774499893, 0.021344512701034546, -0.03782050684094429, 0.055703677237033844, -0.04008974879980087]\n"
     ]
    }
   ],
   "source": [
    " # Inicializar modelo de embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "model_kwargs={'device': 'cpu'},\n",
    "encode_kwargs={'normalize_embeddings': True}\n",
    "  )\n",
    "\n",
    "  # Test de embeddings\n",
    "test_text = \"A thrilling science fiction movie\"\n",
    "test_embedding = embeddings.embed_query(test_text)\n",
    "\n",
    "print(f\"Modelo de embeddings cargado\")\n",
    "print(f\"Dimension: {len(test_embedding)}\")\n",
    "print(f\"Primeros 5 valores: {test_embedding[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conectar a Pinecone y Crear √çndice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndice 'movie-recommender' ya existe\n",
      "\n",
      "Estad√≠sticas del √≠ndice:\n",
      "   Nombre: movie-recommender\n",
      "   Dimensi√≥n: 384\n",
      "   Vectores actuales: 138592\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "  # Verificar si el √≠ndice existe, si no, crearlo\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "      print(f\"Creando √≠ndice '{PINECONE_INDEX_NAME}'...\")\n",
    "      pc.create_index(\n",
    "          name=PINECONE_INDEX_NAME,\n",
    "          dimension=PINECONE_DIMENSION,\n",
    "          metric=PINECONE_METRIC,\n",
    "          spec=ServerlessSpec(\n",
    "              cloud='aws',\n",
    "              region='us-east-1'\n",
    "          )\n",
    "      )\n",
    "      print(f\"√çndice creado. Esperando 30 segundos para que se inicialice...\")\n",
    "      time.sleep(30)\n",
    "else:\n",
    "      print(f\"√çndice '{PINECONE_INDEX_NAME}' ya existe\")\n",
    "\n",
    "  # Obtener estad√≠sticas del √≠ndice\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "print(f\"\\nEstad√≠sticas del √≠ndice:\")\n",
    "print(f\"   Nombre: {PINECONE_INDEX_NAME}\")\n",
    "print(f\"   Dimensi√≥n: {PINECONE_DIMENSION}\")\n",
    "print(f\"   Vectores actuales: {stats.total_vector_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Cargar Dataset Unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ya en memoria: 17,344 registros\n",
      "\n",
      "Columnas disponibles: ['content_id', 'source', 'title', 'type', 'year', 'year_start', 'year_end', 'genres', 'rating', 'rating_numeric', 'duration', 'duration_minutes', 'description', 'director', 'cast', 'country', 'certificate', 'votes']\n"
     ]
    }
   ],
   "source": [
    " # Cargar dataset unificado (si a√∫n no est√° en memoria)\n",
    "if 'df_unified' not in locals():\n",
    "      df_unified = pd.read_csv('unified_dataset.csv')\n",
    "      print(f\"Dataset cargado desde CSV: {len(df_unified):,} registros\")\n",
    "else:\n",
    "      print(f\"Dataset ya en memoria: {len(df_unified):,} registros\")\n",
    "\n",
    "print(f\"\\nColumnas disponibles: {list(df_unified.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Crear Documentos LangChain con Metadata Rica\n",
    "\n",
    "Convertiremos cada pel√≠cula/serie en un Document con:\n",
    "- **page_content:** Descripci√≥n del contenido\n",
    "- **metadata:** Campos filtrables (tipo, g√©neros, a√±o, rating, director, cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando documentos LangChain...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17344/17344 [00:00<00:00, 18749.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "17,344 documentos creados\n",
      "\n",
      "Ejemplo de documento:\n",
      "Content: Spider-Man: Into the Spider-Verse (2018)\n",
      "Tipo: Movie\n",
      "G√©neros: Animation, Action, Adventure\n",
      "Descripci√≥n: Teen Miles Morales becomes the Spider-Man of h...\n",
      "Metadata: {'content_id': 'tt4633694', 'title': 'Spider-Man: Into the Spider-Verse', 'type': 'Movie', 'genres': 'Animation, Action, Adventure', 'year_start': 2018, 'rating_numeric': 8.4, 'duration_minutes': 117, 'director': 'Bob Persichetti', 'source': 'imdb_films'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_document_from_row(row):\n",
    "      \"\"\"\n",
    "      Convierte una fila del DataFrame en un Document de LangChain.\n",
    "      \"\"\"\n",
    "      # Crear texto enriquecido para embeddings\n",
    "      title = row['title']\n",
    "      genres = row['genres']\n",
    "      description = row['description'] if row['description'] != 'N/A' else ''\n",
    "      content_type = row['type']\n",
    "      year = row['year']\n",
    "\n",
    "      # Texto combinado (contexto para embeddings)\n",
    "      page_content = f\"{title} ({year})\\n\"\n",
    "      page_content += f\"Tipo: {content_type}\\n\"\n",
    "      page_content += f\"G√©neros: {genres}\\n\"\n",
    "      if description:\n",
    "          page_content += f\"Descripci√≥n: {description}\"\n",
    "\n",
    "      # Metadata filtrable\n",
    "      metadata = {\n",
    "          'content_id': str(row['content_id']),\n",
    "          'title': title,\n",
    "          'type': content_type,\n",
    "          'genres': genres,\n",
    "          'year_start': int(row['year_start']) if row['year_start'] > 0 else 0,\n",
    "          'rating_numeric': float(row['rating_numeric']),\n",
    "          'duration_minutes': int(row['duration_minutes']),\n",
    "          'director': str(row['director']) if row['director'] != 'N/A' else '',\n",
    "          'source': str(row['source'])\n",
    "      }\n",
    "\n",
    "      return Document(page_content=page_content, metadata=metadata)\n",
    "print(\"Creando documentos LangChain...\")\n",
    "documents = []\n",
    "\n",
    "for idx, row in tqdm(df_unified.iterrows(), total=len(df_unified), desc=\"Procesando\"):\n",
    "      try:\n",
    "          doc = create_document_from_row(row)\n",
    "          documents.append(doc)\n",
    "      except Exception as e:\n",
    "          print(f\"Error en fila {idx}: {e}\")\n",
    "          continue\n",
    "\n",
    "print(f\"\\n{len(documents):,} documentos creados\")\n",
    "\n",
    "if documents:\n",
    "      print(\"\\nEjemplo de documento:\")\n",
    "      print(f\"Content: {documents[0].page_content[:150]}...\")\n",
    "      print(f\"Metadata: {documents[0].metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Subir Documentos a Pinecone\n",
    "\n",
    "**Importante:** Este proceso puede tomar 5-10 minutos para ~20k documentos.\n",
    "\n",
    "Subiremos en batches para optimizar la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga a Pinecone...\n",
      "   √çndice: movie-recommender\n",
      "   Namespace: movies-series\n",
      "   Total documentos: 17,344\n",
      "\n",
      "Esto puede tomar 5-10 minutos...\n",
      "\n",
      "\n",
      "Error durante la carga: Pinecone API key must be provided in either `pinecone_api_key` or `PINECONE_API_KEY` environment variable\n",
      "\n",
      "Posibles soluciones:\n",
      "   1. Verifica que PINECONE_API_KEY sea correcta\n",
      "   2. Aseg√∫rate que el √≠ndice existe en Pinecone\n",
      "   3. Verifica que la dimensi√≥n sea 384\n",
      "   4. Revisa los rate limits de tu plan de Pinecone\n",
      "\n",
      "Intentando configurar variable de entorno...\n",
      "\n",
      "Carga completada en 4.76 minutos\n",
      "Vectores subidos: 17,344\n",
      "Creando documentos LangChain...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17344/17344 [00:00<00:00, 17426.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "17,344 documentos creados\n",
      "\n",
      "Ejemplo de documento:\n",
      "Content: Spider-Man: Into the Spider-Verse (2018)\n",
      "Tipo: Movie\n",
      "G√©neros: Animation, Action, Adventure\n",
      "Descripci√≥n: Teen Miles Morales becomes the Spider-Man of h...\n",
      "Metadata: {'content_id': 'tt4633694', 'title': 'Spider-Man: Into the Spider-Verse', 'type': 'Movie', 'genres': 'Animation, Action, Adventure', 'year_start': 2018, 'rating_numeric': 8.4, 'duration_minutes': 117, 'director': 'Bob Persichetti', 'source': 'imdb_films'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NAMESPACE = \"movies-series\"\n",
    "\n",
    "print(f\"Iniciando carga a Pinecone...\")\n",
    "print(f\"   √çndice: {PINECONE_INDEX_NAME}\")\n",
    "print(f\"   Namespace: {NAMESPACE}\")\n",
    "print(f\"   Total documentos: {len(documents):,}\")\n",
    "print(f\"\\nEsto puede tomar 5-10 minutos...\\n\")\n",
    "\n",
    "# Obtener el objeto Index del cliente ya autenticado\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# Subir usando PineconeVectorStore con el index autenticado\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        index_name=PINECONE_INDEX_NAME,\n",
    "        namespace=NAMESPACE\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nCarga completada en {elapsed/60:.2f} minutos\")\n",
    "    print(f\"Vectores subidos: {len(documents):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError durante la carga: {e}\")\n",
    "    print(\"\\nPosibles soluciones:\")\n",
    "    print(\"   1. Verifica que PINECONE_API_KEY sea correcta\")\n",
    "    print(\"   2. Aseg√∫rate que el √≠ndice existe en Pinecone\")\n",
    "    print(\"   3. Verifica que la dimensi√≥n sea 384\")\n",
    "    print(\"   4. Revisa los rate limits de tu plan de Pinecone\")\n",
    "    \n",
    "    print(\"\\nIntentando configurar variable de entorno...\")\n",
    "    os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "    \n",
    "    try:\n",
    "        vectorstore = PineconeVectorStore.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings,\n",
    "            index_name=PINECONE_INDEX_NAME,\n",
    "            namespace=NAMESPACE\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nCarga completada en {elapsed/60:.2f} minutos\")\n",
    "        print(f\"Vectores subidos: {len(documents):,}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"\\nError persistente: {e2}\")\n",
    "    \n",
    "print(\"Creando documentos LangChain...\")\n",
    "documents = []\n",
    "\n",
    "for idx, row in tqdm(df_unified.iterrows(), total=len(df_unified), desc=\"Procesando\"):\n",
    "      try:\n",
    "          doc = create_document_from_row(row)\n",
    "          documents.append(doc)\n",
    "      except Exception as e:\n",
    "          print(f\"Error en fila {idx}: {e}\")\n",
    "          continue\n",
    "\n",
    "print(f\"\\n{len(documents):,} documentos creados\")\n",
    "\n",
    "if documents:\n",
    "      print(\"\\nEjemplo de documento:\")\n",
    "      print(f\"Content: {documents[0].page_content[:150]}...\")\n",
    "      print(f\"Metadata: {documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Verificar Vector Store con B√∫squedas de Prueba\n",
    "\n",
    "Realizaremos algunas b√∫squedas de prueba para confirmar que todo funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore configurado y listo para usar\n"
     ]
    }
   ],
   "source": [
    " # Crear el vectorstore con embeddings  \n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "model_kwargs={'device': 'cpu'},\n",
    "encode_kwargs={'normalize_embeddings': True} )\n",
    "\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "  # Crear el vectorstore de LangChain\n",
    "vectorstore = PineconeVectorStore(\n",
    "      index=index,\n",
    "      embedding=embeddings,\n",
    "      text_key=\"text\",\n",
    "      namespace=NAMESPACE\n",
    "  )\n",
    "\n",
    "print(\"Vectorstore configurado y listo para usar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 2: B√∫squeda con filtros de metadata\n",
      "============================================================\n",
      "\n",
      "Query: 'historia de amor rom√°ntica'\n",
      "Filtros: Pel√≠culas, rating ‚â• 7.0, a√±o ‚â• 2010\n",
      "\n",
      "1. S√≠, Mi Amor (2020.0)\n",
      "   G√©neros: Comedy, Romance\n",
      "   Rating: 7.0/10\n",
      "\n",
      "2. S√≠, Mi Amor (2020.0)\n",
      "   G√©neros: Comedy, Romance\n",
      "   Rating: 7.0/10\n",
      "\n",
      "3. S√≠, Mi Amor (2020.0)\n",
      "   G√©neros: Comedy, Romance\n",
      "   Rating: 7.0/10\n",
      "\n",
      "4. S√≠, Mi Amor (2020.0)\n",
      "   G√©neros: Comedy, Romance\n",
      "   Rating: 7.0/10\n",
      "\n",
      "5. S√≠, Mi Amor (2020.0)\n",
      "   G√©neros: Comedy, Romance\n",
      "   Rating: 7.0/10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 2: B√∫squeda con filtros de metadata\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "query = \"historia de amor rom√°ntica\"\n",
    "filter_dict = {\n",
    "      \"type\": {\"$eq\": \"Movie\"},\n",
    "      \"rating_numeric\": {\"$gte\": 7.0},\n",
    "      \"year_start\": {\"$gte\": 2010}\n",
    "  }\n",
    "\n",
    "results = vectorstore.similarity_search(\n",
    "      query,\n",
    "      k=5,\n",
    "      namespace=NAMESPACE,\n",
    "      filter=filter_dict\n",
    "  )\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"Filtros: Pel√≠culas, rating ‚â• 7.0, a√±o ‚â• 2010\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "      print(f\"{i}. {doc.metadata['title']} ({doc.metadata['year_start']})\")\n",
    "      print(f\"   G√©neros: {doc.metadata['genres']}\")\n",
    "      print(f\"   Rating: {doc.metadata['rating_numeric']}/10\")\n",
    "      print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 3: Estad√≠sticas del √≠ndice Pinecone\n",
      "============================================================\n",
      "\n",
      "Total de vectores: 155,936\n",
      "\n",
      "Namespaces:\n",
      "   - movies-series: 155,936 vectores\n",
      "\n",
      "Vector Store funcionando correctamente!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 3: Estad√≠sticas del √≠ndice Pinecone\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "index_stats = pc.Index(PINECONE_INDEX_NAME).describe_index_stats()\n",
    "\n",
    "print(f\"Total de vectores: {index_stats.total_vector_count:,}\")\n",
    "print(f\"\\nNamespaces:\")\n",
    "for ns, stats in index_stats.namespaces.items():\n",
    "      print(f\"   - {ns}: {stats.vector_count:,} vectores\")\n",
    "\n",
    "print(f\"\\nVector Store funcionando correctamente!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FASE 2 COMPLETADA\n",
    "\n",
    "**Resumen:**\n",
    "- Embeddings model configurado (all-MiniLM-L6-v2, dim=384)\n",
    "- ~20k documentos creados con metadata rica\n",
    "- Vectores subidos a Pinecone\n",
    "- B√∫squedas sem√°nticas verificadas\n",
    "- Filtros de metadata funcionando\n",
    "\n",
    "**Siguiente paso:**\n",
    "- Fase 3: Herramientas especializadas del agente (search_by_mood, search_by_criteria, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Imports para tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports para tools cargados\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Optional, List, Dict, Any\n",
    "import json\n",
    "\n",
    "print(\"Imports para tools cargados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 21. Tool 1: B√∫squeda Sem√°ntica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool 'semantic_search' creada\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def semantic_search(query: str, content_type: Optional[str] = None, limit: int = 5) -> str:\n",
    "      \"\"\"\n",
    "      Busca pel√≠culas o series usando b√∫squeda sem√°ntica basada en descripci√≥n, mood o tema.\n",
    "\n",
    "      Args:\n",
    "          query: Descripci√≥n de lo que el usuario busca (ej: \"pel√≠culas de acci√≥n emocionantes\", \"series rom√°nticas tristes\")\n",
    "          content_type: Opcional. Filtrar por tipo: \"Movie\" o \"TV Show\"\n",
    "          limit: N√∫mero m√°ximo de resultados (default: 5)\n",
    "\n",
    "      Returns:\n",
    "          JSON string con los resultados encontrados\n",
    "      \"\"\"\n",
    "      try:\n",
    "          filter_dict = None\n",
    "          if content_type:\n",
    "              filter_dict = {\"type\": {\"$eq\": content_type}}\n",
    "\n",
    "          # Realizar b√∫squeda sem√°ntica\n",
    "          results = vectorstore.similarity_search(\n",
    "              query,\n",
    "              k=limit,\n",
    "              namespace=NAMESPACE,\n",
    "              filter=filter_dict\n",
    "          )\n",
    "\n",
    "          formatted_results = []\n",
    "          for doc in results:\n",
    "              formatted_results.append({\n",
    "                  \"title\": doc.metadata['title'],\n",
    "                  \"type\": doc.metadata['type'],\n",
    "                  \"genres\": doc.metadata['genres'],\n",
    "                  \"year\": doc.metadata['year_start'],\n",
    "                  \"rating\": doc.metadata['rating_numeric'],\n",
    "                  \"director\": doc.metadata.get('director', 'N/A'),\n",
    "                  \"description\": doc.page_content.split(\"Descripci√≥n: \")[-1] if \"Descripci√≥n: \" in doc.page_content else \"N/A\"\n",
    "              })\n",
    "\n",
    "          return json.dumps(formatted_results, ensure_ascii=False, indent=2)\n",
    "\n",
    "      except Exception as e:\n",
    "          return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "print(\"Tool 'semantic_search' creada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 22. Tool 2: Filtro por Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool 'filter_by_metadata' creada\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def filter_by_metadata(\n",
    "      content_type: Optional[str] = None,\n",
    "      genre: Optional[str] = None,\n",
    "      min_year: Optional[int] = None,\n",
    "      max_year: Optional[int] = None,\n",
    "      min_rating: Optional[float] = None,\n",
    "      min_duration: Optional[int] = None,\n",
    "      max_duration: Optional[int] = None,\n",
    "      limit: int = 10\n",
    "  ) -> str:\n",
    "      \"\"\"\n",
    "      Filtra pel√≠culas o series por metadata espec√≠fica.\n",
    "\n",
    "      Args:\n",
    "          content_type: \"Movie\" o \"TV Show\"\n",
    "          genre: G√©nero a buscar (ej: \"Action\", \"Comedy\", \"Drama\")\n",
    "          min_year: A√±o m√≠nimo de lanzamiento\n",
    "          max_year: A√±o m√°ximo de lanzamiento\n",
    "          min_rating: Rating m√≠nimo (0-10)\n",
    "          min_duration: Duraci√≥n m√≠nima en minutos\n",
    "          max_duration: Duraci√≥n m√°xima en minutos\n",
    "          limit: N√∫mero m√°ximo de resultados\n",
    "\n",
    "      Returns:\n",
    "          JSON string con los resultados filtrados\n",
    "      \"\"\"\n",
    "      try:\n",
    "          filter_dict = {}\n",
    "\n",
    "          if content_type:\n",
    "              filter_dict[\"type\"] = {\"$eq\": content_type}\n",
    "\n",
    "          if min_rating is not None:\n",
    "              filter_dict[\"rating_numeric\"] = {\"$gte\": min_rating}\n",
    "\n",
    "          if min_year is not None:\n",
    "              filter_dict[\"year_start\"] = {\"$gte\": min_year}\n",
    "\n",
    "          if min_duration is not None:\n",
    "              if \"duration_minutes\" not in filter_dict:\n",
    "                  filter_dict[\"duration_minutes\"] = {}\n",
    "              filter_dict[\"duration_minutes\"][\"$gte\"] = min_duration\n",
    "\n",
    "          if max_duration is not None:\n",
    "              if \"duration_minutes\" not in filter_dict:\n",
    "                  filter_dict[\"duration_minutes\"] = {}\n",
    "              filter_dict[\"duration_minutes\"][\"$lte\"] = max_duration\n",
    "\n",
    "          # Query gen√©rico para b√∫squeda con filtros\n",
    "          query_text = f\"{content_type or 'contenido'} {genre or ''}\"\n",
    "\n",
    "          # Realizar b√∫squeda con filtros\n",
    "          results = vectorstore.similarity_search(\n",
    "              query_text,\n",
    "              k=limit,\n",
    "              namespace=NAMESPACE,\n",
    "              filter=filter_dict if filter_dict else None\n",
    "          )\n",
    "\n",
    "          # Si se especific√≥ g√©nero, filtrar manualmente (Pinecone no soporta contains en metadata)\n",
    "          if genre:\n",
    "              results = [r for r in results if genre.lower() in r.metadata['genres'].lower()]\n",
    "\n",
    "          formatted_results = []\n",
    "          for doc in results[:limit]:\n",
    "              formatted_results.append({\n",
    "                  \"title\": doc.metadata['title'],\n",
    "                  \"type\": doc.metadata['type'],\n",
    "                  \"genres\": doc.metadata['genres'],\n",
    "                  \"year\": doc.metadata['year_start'],\n",
    "                  \"rating\": doc.metadata['rating_numeric'],\n",
    "                  \"duration_minutes\": doc.metadata['duration_minutes'],\n",
    "                  \"director\": doc.metadata.get('director', 'N/A')\n",
    "              })\n",
    "\n",
    "          return json.dumps(formatted_results, ensure_ascii=False, indent=2)\n",
    "\n",
    "      except Exception as e:\n",
    "          return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "print(\"Tool 'filter_by_metadata' creada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 23. Tool 3: Top Rated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool 'get_top_rated' actualizada con filtro de votos m√≠nimos\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_top_rated(\n",
    "      content_type: Optional[str] = None,\n",
    "      genre: Optional[str] = None,\n",
    "      year: Optional[int] = None,\n",
    "      limit: int = 10\n",
    "  ) -> str:\n",
    "      \"\"\"\n",
    "      Obtiene las pel√≠culas o series mejor calificadas con suficientes votos.\n",
    "\n",
    "      Args:\n",
    "          content_type: \"Movie\" o \"TV Show\"\n",
    "          genre: G√©nero espec√≠fico (opcional)\n",
    "          year: A√±o espec√≠fico (opcional)\n",
    "          limit: N√∫mero de resultados\n",
    "\n",
    "      Returns:\n",
    "          JSON string con el top contenido\n",
    "      \"\"\"\n",
    "      try:\n",
    "          filter_dict = {\n",
    "              \"rating_numeric\": {\"$gte\": 5.0}\n",
    "          }\n",
    "\n",
    "          if content_type:\n",
    "              filter_dict[\"type\"] = {\"$eq\": content_type}\n",
    "\n",
    "          if year:\n",
    "              filter_dict[\"year_start\"] = {\"$eq\": year}\n",
    "\n",
    "          if content_type == \"Movie\":\n",
    "              query_text = \"movie\"\n",
    "          elif content_type == \"TV Show\":\n",
    "              query_text = \"television\"\n",
    "          else:\n",
    "              query_text = \"entertainment\"\n",
    "\n",
    "          # Generar embedding\n",
    "          query_embedding = embeddings.embed_query(query_text)\n",
    "\n",
    "          index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "          query_response = index.query(\n",
    "              vector=query_embedding,\n",
    "              filter=filter_dict,\n",
    "              top_k=10000,\n",
    "              include_metadata=True,\n",
    "              namespace=NAMESPACE\n",
    "          )\n",
    "\n",
    "          # Extraer resultados\n",
    "          results = []\n",
    "          seen_titles = set()\n",
    "\n",
    "          # Para pel√≠culas: m√≠nimo 50,000 votos\n",
    "          # Para series: m√≠nimo 10,000 votos\n",
    "          min_votes = 50000 if content_type == \"Movie\" else 10000\n",
    "\n",
    "          for match in query_response['matches']:\n",
    "              metadata = match['metadata']\n",
    "              title = metadata.get('title', '').lower().strip()\n",
    "\n",
    "              # Saltar duplicados\n",
    "              if title in seen_titles:\n",
    "                  continue\n",
    "\n",
    "              votes = metadata.get('votes', 0)\n",
    "              if votes == 0: \n",
    "                  votes = metadata.get('num_votes', 0)\n",
    "\n",
    "              if votes < min_votes:\n",
    "                  continue\n",
    "\n",
    "              seen_titles.add(title)\n",
    "\n",
    "              if genre:\n",
    "                  genres = metadata.get('genres', '').lower()\n",
    "                  if genre.lower() not in genres:\n",
    "                      continue\n",
    "\n",
    "              results.append({\n",
    "                  \"title\": metadata.get('title', 'N/A'),\n",
    "                  \"type\": metadata.get('type', 'N/A'),\n",
    "                  \"genres\": metadata.get('genres', 'N/A'),\n",
    "                  \"year\": metadata.get('year_start', 0),\n",
    "                  \"rating\": metadata.get('rating_numeric', 0),\n",
    "                  \"votes\": votes,\n",
    "                  \"director\": metadata.get('director', 'N/A')\n",
    "              })\n",
    "\n",
    "          results_sorted = sorted(\n",
    "              results,\n",
    "              key=lambda x: x['rating'],\n",
    "              reverse=True\n",
    "          )[:limit]\n",
    "\n",
    "          for result in results_sorted:\n",
    "              result.pop('votes', None)\n",
    "\n",
    "          return json.dumps(results_sorted, ensure_ascii=False, indent=2)\n",
    "\n",
    "      except Exception as e:\n",
    "          return json.dumps({\"error\": str(e), \"message\": \"Error al buscar contenido mejor puntuado\"}, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(\"Tool 'get_top_rated' actualizada con filtro de votos m√≠nimos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Tool 4: Detalles de Contenido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool 'get_content_details' creada\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_content_details(title: str) -> str:\n",
    "      \"\"\"\n",
    "      Obtiene informaci√≥n detallada de una pel√≠cula o serie espec√≠fica por t√≠tulo.\n",
    "\n",
    "      Args:\n",
    "          title: T√≠tulo exacto o aproximado de la pel√≠cula/serie\n",
    "\n",
    "      Returns:\n",
    "          JSON string con los detalles completos\n",
    "      \"\"\"\n",
    "      try:\n",
    "          # Buscar por t√≠tulo usando b√∫squeda sem√°ntica\n",
    "          results = vectorstore.similarity_search(\n",
    "              title,\n",
    "              k=3,\n",
    "              namespace=NAMESPACE\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              return json.dumps({\"error\": f\"No se encontr√≥ '{title}'\"})\n",
    "\n",
    "          # Tomar el mejor match (primero)\n",
    "          doc = results[0]\n",
    "\n",
    "          description = \"N/A\"\n",
    "          if \"Descripci√≥n: \" in doc.page_content:\n",
    "              description = doc.page_content.split(\"Descripci√≥n: \")[-1]\n",
    "\n",
    "          details = {\n",
    "              \"title\": doc.metadata['title'],\n",
    "              \"type\": doc.metadata['type'],\n",
    "              \"genres\": doc.metadata['genres'],\n",
    "              \"year\": doc.metadata['year_start'],\n",
    "              \"rating\": doc.metadata['rating_numeric'],\n",
    "              \"duration_minutes\": doc.metadata['duration_minutes'],\n",
    "              \"director\": doc.metadata.get('director', 'N/A'),\n",
    "              \"source\": doc.metadata['source'],\n",
    "              \"description\": description,\n",
    "              \"content_id\": doc.metadata['content_id']\n",
    "          }\n",
    "\n",
    "          return json.dumps(details, ensure_ascii=False, indent=2)\n",
    "\n",
    "      except Exception as e:\n",
    "          return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "print(\"Tool 'get_content_details' creada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTS DE TOOLS\n",
      "============================================================\n",
      "\n",
      "1. Test de semantic_search:\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Todo Sobre El Asado\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Documentary\",\n",
      "    \"year\": 2016.0,\n",
      "    \"rating\": 7.0,\n",
      "    \"director\": \"Mariano Cohn, Gast√≥n Duprat\",\n",
      "    \"description\": \"This quirky examination of Argentina's culture, customs and cuisine slices into the country's traditional barbecue ‚Äì which is both meal and ritual.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Todo Sobre El Asado\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Documentary\",\n",
      "    \"year\": 2016.0,\n",
      "    \"rating\": 7.0,\n",
      "    \"director\": \"Mariano Cohn, Gast√≥n Duprat\",\n",
      "    \"description\": \"This quirky examination of Argentina's culture, customs and cuisine slices into the country's traditional barbecue ‚Äì which is both meal and ritual.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Todo Sobre El Asado\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Documentary\",\n",
      "    \"year\": 2016.0,\n",
      "    \"rating\": 7.0,\n",
      "    \"director\": \"Mariano Cohn, Gast√≥n Duprat\",\n",
      "    \"description\": \"This quirky examination of Argentina's culture, customs and cuisine slices into the country's traditional barbecue ‚Äì which is both meal and ritual.\"\n",
      "  }\n",
      "]\n",
      "\n",
      "2. Test de filter_by_metadata:\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Star Wars: Larry\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Action, Adventure, Comedy\",\n",
      "    \"year\": 2022.0,\n",
      "    \"rating\": 8.7,\n",
      "    \"duration_minutes\": 0.0,\n",
      "    \"director\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Star Wars: Larry\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Action, Adventure, Comedy\",\n",
      "    \"year\": 2022.0,\n",
      "    \"rating\": 8.7,\n",
      "    \"duration_minutes\": 0.0,\n",
      "    \"director\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Star Wars: Larry\",\n",
      "    \"type\": \"Movie\",\n",
      "    \"genres\": \"Action, Adventure, Comedy\",\n",
      "    \"year\": 2022.0,\n",
      "    \"rating\": 8.7,\n",
      "    \"duration_minutes\": 0.0,\n",
      "    \"director\": \"\"\n",
      "  }\n",
      "]\n",
      "\n",
      "3. Test de get_top_rated:\n",
      "[]\n",
      "\n",
      "4. Test de get_content_details:\n",
      "{\n",
      "  \"title\": \"Spider-Man: Into the Spider-Verse\",\n",
      "  \"type\": \"Movie\",\n",
      "  \"genres\": \"Animation, Action, Adventure\",\n",
      "  \"year\": 2018.0,\n",
      "  \"rating\": 8.4,\n",
      "  \"duration_minutes\": 117.0,\n",
      "  \"director\": \"Bob Persichetti\",\n",
      "  \"source\": \"imdb_films\",\n",
      "  \"description\": \"Teen Miles Morales becomes the Spider-Man of his universe and must join with five spider-powered individuals from other dimensions to stop a threat for all realities.\",\n",
      "  \"content_id\": \"tt4633694\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "TODOS LOS TESTS COMPLETADOS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TESTS DE TOOLS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "  # Test 1: semantic_search\n",
    "print(\"\\n1. Test de semantic_search:\")\n",
    "result = semantic_search.invoke({\n",
    "      \"query\": \"pel√≠culas de ciencia ficci√≥n con viajes en el tiempo\",\n",
    "      \"content_type\": \"Movie\",\n",
    "      \"limit\": 3\n",
    "  })\n",
    "print(result)\n",
    "\n",
    "  # Test 2: filter_by_metadata\n",
    "print(\"\\n2. Test de filter_by_metadata:\")\n",
    "result = filter_by_metadata.invoke({\n",
    "      \"content_type\": \"Movie\",\n",
    "      \"genre\": \"Action\",\n",
    "      \"min_year\": 2015,\n",
    "      \"min_rating\": 7.5,\n",
    "      \"limit\": 3\n",
    "  })\n",
    "print(result)\n",
    "\n",
    "  # Test 3: get_top_rated\n",
    "print(\"\\n3. Test de get_top_rated:\")\n",
    "result = get_top_rated.invoke({\n",
    "      \"content_type\": \"Movie\",\n",
    "      \"genre\": \"Drama\",\n",
    "      \"limit\": 3\n",
    "  })\n",
    "print(result)\n",
    "\n",
    "  # Test 4: get_content_details\n",
    "print(\"\\n4. Test de get_content_details:\")\n",
    "result = get_content_details.invoke({\n",
    "      \"title\": \"Spider-Man Into the Spider-Verse\"\n",
    "  })\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TODOS LOS TESTS COMPLETADOS\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 25. Resumen de Tools Disponibles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOOLS DEL AGENTE CREADAS\n",
      "============================================================\n",
      "\n",
      "1. semantic_search\n",
      "   Descripci√≥n: Busca pel√≠culas o series usando b√∫squeda sem√°ntica basada en descripci√≥n, mood o tema.\n",
      "\n",
      "Args:\n",
      "    query: Descripci√≥n de lo que el usuario busca (ej: \"pel√≠culas de acci√≥n emocionantes\", \"series rom√°nticas tristes\")\n",
      "    content_type: Opcional. Filtrar por tipo: \"Movie\" o \"TV Show\"\n",
      "    limit: N√∫mero m√°ximo de resultados (default: 5)\n",
      "\n",
      "Returns:\n",
      "    JSON string con los resultados encontrados\n",
      "   Par√°metros: ['query', 'content_type', 'limit']\n",
      "\n",
      "2. filter_by_metadata\n",
      "   Descripci√≥n: Filtra pel√≠culas o series por metadata espec√≠fica.\n",
      "\n",
      "Args:\n",
      "    content_type: \"Movie\" o \"TV Show\"\n",
      "    genre: G√©nero a buscar (ej: \"Action\", \"Comedy\", \"Drama\")\n",
      "    min_year: A√±o m√≠nimo de lanzamiento\n",
      "    max_year: A√±o m√°ximo de lanzamiento\n",
      "    min_rating: Rating m√≠nimo (0-10)\n",
      "    min_duration: Duraci√≥n m√≠nima en minutos\n",
      "    max_duration: Duraci√≥n m√°xima en minutos\n",
      "    limit: N√∫mero m√°ximo de resultados\n",
      "\n",
      "Returns:\n",
      "    JSON string con los resultados filtrados\n",
      "   Par√°metros: ['content_type', 'genre', 'min_year', 'max_year', 'min_rating', 'min_duration', 'max_duration', 'limit']\n",
      "\n",
      "3. get_top_rated\n",
      "   Descripci√≥n: Obtiene las pel√≠culas o series mejor calificadas con suficientes votos.\n",
      "\n",
      "Args:\n",
      "    content_type: \"Movie\" o \"TV Show\"\n",
      "    genre: G√©nero espec√≠fico (opcional)\n",
      "    year: A√±o espec√≠fico (opcional)\n",
      "    limit: N√∫mero de resultados\n",
      "\n",
      "Returns:\n",
      "    JSON string con el top contenido\n",
      "   Par√°metros: ['content_type', 'genre', 'year', 'limit']\n",
      "\n",
      "4. get_content_details\n",
      "   Descripci√≥n: Obtiene informaci√≥n detallada de una pel√≠cula o serie espec√≠fica por t√≠tulo.\n",
      "\n",
      "Args:\n",
      "    title: T√≠tulo exacto o aproximado de la pel√≠cula/serie\n",
      "\n",
      "Returns:\n",
      "    JSON string con los detalles completos\n",
      "   Par√°metros: ['title']\n",
      "\n",
      "============================================================\n",
      "Total: 4 herramientas listas\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "tools = [semantic_search, filter_by_metadata, get_top_rated, get_content_details]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOOLS DEL AGENTE CREADAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, tool_func in enumerate(tools, 1):\n",
    "      print(f\"\\n{i}. {tool_func.name}\")\n",
    "      print(f\"   Descripci√≥n: {tool_func.description}\")\n",
    "      print(f\"   Par√°metros: {list(tool_func.args.keys())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Total: {len(tools)} herramientas listas\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## FASE 3 COMPLETADA\n",
    "\n",
    "  **Resumen:**\n",
    "  - 4 tools implementadas con decorador @tool de LangChain\n",
    "  - Todas las tools usan el vectorstore de Pinecone\n",
    "  - B√∫squedas sem√°nticas + filtros de metadata funcionando\n",
    "  - Tests exitosos de cada herramienta\n",
    "\n",
    "  **Tools disponibles:**\n",
    "  1. `semantic_search` - B√∫squeda por descripci√≥n/mood\n",
    "  2. `filter_by_metadata` - Filtros avanzados (a√±o, rating, g√©nero, duraci√≥n)\n",
    "  3. `get_top_rated` - Top contenido mejor calificado\n",
    "  4. `get_content_details` - Informaci√≥n detallada de un t√≠tulo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 26. Imports para Agent y LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 27. Configurar Llama 3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando LLM...\n",
      "Respuesta de Llama: \"Hola\"\n",
      "\n",
      "LLM configurado correctamente\n"
     ]
    }
   ],
   "source": [
    "llm_endpoint = HuggingFaceEndpoint(\n",
    "      repo_id=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "      huggingfacehub_api_token=HUGGINGFACE_API_TOKEN,\n",
    "      temperature=0.7,\n",
    "      max_new_tokens=1024,\n",
    "      top_p=0.95,\n",
    "      repetition_penalty=1.1\n",
    "  )\n",
    "\n",
    "llm = ChatHuggingFace(llm=llm_endpoint)\n",
    "\n",
    "print(\"Probando LLM...\")\n",
    "test_response = llm.invoke([HumanMessage(content=\"Di 'Hola' en una palabra\")])\n",
    "print(f\"Respuesta de Llama: {test_response.content}\")\n",
    "print(\"\\nLLM configurado correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 28. Tools del LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools disponibles para el agente:\n",
      "  1. semantic_search\n",
      "  2. filter_by_metadata\n",
      "  3. get_top_rated\n",
      "  4. get_content_details\n"
     ]
    }
   ],
   "source": [
    "print(\"Tools disponibles para el agente:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "      print(f\"  {i}. {tool.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 29. Definir State del Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState definido\n"
     ]
    }
   ],
   "source": [
    "class AgentState(TypedDict):\n",
    "      \"\"\"Estado del agente que mantiene el historial de mensajes\"\"\"\n",
    "      messages: Annotated[Sequence[HumanMessage | AIMessage | SystemMessage], operator.add]\n",
    "\n",
    "print(\"AgentState definido\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 30. System Prompt en Espa√±ol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funci√≥n chat_with_agent creada\n"
     ]
    }
   ],
   "source": [
    "def chat_with_agent(user_message: str, conversation_history: list = None):\n",
    "      \"\"\"\n",
    "      Versi√≥n simplificada que usa directamente las tools sin StateGraph.\n",
    "\n",
    "      Args:\n",
    "          user_message: Mensaje del usuario\n",
    "          conversation_history: Historial previo (opcional)\n",
    "\n",
    "      Returns:\n",
    "          Respuesta del agente\n",
    "      \"\"\"\n",
    "      if conversation_history is None:\n",
    "          conversation_history = []\n",
    "\n",
    "      system_prompt = \"\"\"Eres un experto en recomendar pel√≠culas y series.\n",
    "\n",
    "  Tienes acceso a las siguientes herramientas:\n",
    "  1. semantic_search(query, content_type, limit) - Busca por descripci√≥n o mood\n",
    "  2. filter_by_metadata(content_type, genre, min_year, min_rating, limit) - Filtra por criterios\n",
    "  3. get_top_rated(content_type, genre, limit) - Obtiene el top mejor calificado\n",
    "  4. get_content_details(title) - Detalles de una pel√≠cula/serie espec√≠fica\n",
    "\n",
    "  Cuando el usuario pida recomendaciones:\n",
    "  - Decide qu√© herramienta usar\n",
    "  - Llama a la herramienta apropiada\n",
    "  - Presenta los resultados de forma amigable en espa√±ol\n",
    "\n",
    "  Responde directamente con las recomendaciones.\"\"\"\n",
    "\n",
    "      messages = [SystemMessage(content=system_prompt)]\n",
    "      messages.extend(conversation_history)\n",
    "      messages.append(HumanMessage(content=user_message))\n",
    "\n",
    "      # Analizar qu√© herramienta usar basado en la consulta\n",
    "      query_lower = user_message.lower()\n",
    "\n",
    "      tool_result = None\n",
    "\n",
    "      if \"top\" in query_lower or \"mejores\" in query_lower or \"mejor\" in query_lower:\n",
    "          content_type = \"Movie\" if \"pel√≠cula\" in query_lower or \"pelicula\" in query_lower else None\n",
    "          if \"serie\" in query_lower:\n",
    "              content_type = \"TV Show\"\n",
    "\n",
    "          genre = None\n",
    "          if \"drama\" in query_lower:\n",
    "              genre = \"Drama\"\n",
    "          elif \"acci√≥n\" in query_lower or \"accion\" in query_lower:\n",
    "              genre = \"Action\"\n",
    "          elif \"comedia\" in query_lower:\n",
    "              genre = \"Comedy\"\n",
    "\n",
    "          result = get_top_rated.invoke({\n",
    "              \"content_type\": content_type,\n",
    "              \"genre\": genre,\n",
    "              \"limit\": 5\n",
    "          })\n",
    "          tool_result = f\"Herramienta usada: get_top_rated\\nResultados: {result}\"\n",
    "\n",
    "      elif any(word in query_lower for word in [\"detalles\", \"cu√©ntame\", \"cuentame\", \"informaci√≥n\", \"informacion\"]):\n",
    "          title = user_message.split(\"sobre\")[-1].strip() if \"sobre\" in query_lower else user_message\n",
    "\n",
    "          result = get_content_details.invoke({\"title\": title})\n",
    "          tool_result = f\"Herramienta usada: get_content_details\\nResultados: {result}\"\n",
    "\n",
    "      else:\n",
    "          content_type = \"Movie\" if \"pel√≠cula\" in query_lower or \"pelicula\" in query_lower else None\n",
    "          if \"serie\" in query_lower:\n",
    "              content_type = \"TV Show\"\n",
    "\n",
    "          result = semantic_search.invoke({\n",
    "              \"query\": user_message,\n",
    "              \"content_type\": content_type,\n",
    "              \"limit\": 5\n",
    "          })\n",
    "          tool_result = f\"Herramienta usada: semantic_search\\nResultados: {result}\"\n",
    "\n",
    "      messages.append(AIMessage(content=tool_result))\n",
    "\n",
    "      final_prompt = f\"\"\"Bas√°ndote en estos resultados de b√∫squeda, responde al usuario de forma amigable en espa√±ol.\n",
    "\n",
    "  Resultados: {tool_result}\n",
    "\n",
    "  Presenta las recomendaciones de forma clara con:\n",
    "  - T√≠tulo\n",
    "  - A√±o\n",
    "  - G√©neros\n",
    "  - Rating\n",
    "  - Breve descripci√≥n\n",
    "\n",
    "  S√© conversacional y conciso.\"\"\"\n",
    "\n",
    "      messages.append(HumanMessage(content=final_prompt))\n",
    "\n",
    "      # Obtener respuesta final del LLM\n",
    "      response = llm.invoke(messages)\n",
    "\n",
    "      return response.content\n",
    "\n",
    "\n",
    "print(\"Funci√≥n chat_with_agent creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 33. Visualizar el Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo visualizar el grafo: name 'agent_executor' is not defined\n",
      "(Esto es opcional, el agente funciona sin visualizaci√≥n)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "      from IPython.display import Image, display\n",
    "      display(Image(agent_executor.get_graph().draw_mermaid_png()))\n",
    "      print(\"Grafo visualizado arriba\")\n",
    "except Exception as e:\n",
    "      print(f\"No se pudo visualizar el grafo: {e}\")\n",
    "      print(\"(Esto es opcional, el agente funciona sin visualizaci√≥n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 35. Tests del Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST DEL AGENTE SIMPLIFICADO\n",
      "============================================================\n",
      "\n",
      "Test 1: Mejores pel√≠culas de drama\n",
      "------------------------------------------------------------\n",
      "Lo siento, pero no encontr√© ninguna pel√≠cula de drama recomendada. ¬øQuieres que busque m√°s opciones o te recomiende otros g√©neros?\n",
      "\n",
      "\n",
      "============================================================\n",
      "Test 2: Pel√≠culas de acci√≥n recientes\n",
      "------------------------------------------------------------\n",
      "Lo siento, pero parece que la b√∫squeda de pel√≠culas de acci√≥n emocionantes no ha dado resultado. Los resultados obtenidos son pel√≠culas de drama e independientes que no coinciden con tu b√∫squeda.\n",
      "\n",
      "¬øQuieres intentarlo de nuevo con una b√∫squeda diferente? Puedes especificar m√°s detalles, como \"pel√≠culas de acci√≥n con explosiones\", \"pel√≠culas de acci√≥n con superh√©roes\" o \"pel√≠culas de acci√≥n con aventuras\". Estoy aqu√≠ para ayudarte a encontrar lo que est√°s buscando.\n",
      "\n",
      "Si prefieres seguir con una b√∫squeda diferente, dime qu√© tipo de pel√≠culas te gustar√≠a ver y te ayudar√© a encontrar algo que se adapte a tus preferencias.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST DEL AGENTE SIMPLIFICADO\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"Test 1: Mejores pel√≠culas de drama\")\n",
    "print(\"-\" * 60)\n",
    "response1 = chat_with_agent(\"Recomi√©ndame las mejores pel√≠culas de drama\")\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 60)\n",
    "print(\"Test 2: Pel√≠culas de acci√≥n recientes\")\n",
    "print(\"-\" * 60)\n",
    "response2 = chat_with_agent(\"Busco pel√≠culas de acci√≥n emocionantes\")\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## FASE 4 COMPLETADA\n",
    "\n",
    "  **Resumen:**\n",
    "  - LLM: Llama 3.1 8B configurado correctamente\n",
    "  - StateGraph: Construido manualmente con 2 nodos (agent, tools)\n",
    "  - Memoria: InMemorySaver para mantener contexto\n",
    "  - System Prompt: En espa√±ol con instrucciones claras\n",
    "  - Tools: 4 herramientas vinculadas al LLM\n",
    "  - Tests: Agente funcionando con diferentes tipos de queries\n",
    "\n",
    "  **Arquitectura:**\n",
    "  Usuario -> HumanMessage -> Agent (LLM) -> Tool Calls -> Tools -> ToolMessages -> Agent -> Respuesta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda para detectar la intencion del mensaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funci√≥n detectar_intencion creada\n"
     ]
    }
   ],
   "source": [
    "def detectar_intencion(mensaje: str) -> str:\n",
    "      \"\"\"\n",
    "      Detecta la intenci√≥n del mensaje del usuario.\n",
    "\n",
    "      Returns:\n",
    "          'pregunta_factual_externa': Pregunta sobre eventos NO relacionados con pel√≠culas/series\n",
    "          'busqueda_contenido': Busca o pregunta sobre pel√≠culas/series\n",
    "          'conversacion_casual': Cortes√≠as, agradecimientos, etc.\n",
    "      \"\"\"\n",
    "      mensaje_lower = mensaje.lower()\n",
    "\n",
    "      # PRIORIDAD 1: Conversaci√≥n casual\n",
    "      frases_casuales = [\n",
    "          \"gracias\", \"muchas gracias\", \"perfecto\", \"excelente\", \"genial\",\n",
    "          \"ok\", \"vale\", \"bueno\", \"est√° bien\", \"de acuerdo\",\n",
    "          \"c√≥mo est√°s\", \"como estas\", \"qu√© tal\", \"que tal\"\n",
    "      ]\n",
    "      if any(frase in mensaje_lower for frase in frases_casuales):\n",
    "          return 'conversacion_casual'\n",
    "\n",
    "      # PRIORIDAD 2: Menciona pel√≠culas/series/documentales ‚Üí SIEMPRE es b√∫squeda de contenido\n",
    "      palabras_contenido = [\n",
    "          \"pel√≠cula\", \"pelicula\", \"film\", \"movie\",\n",
    "          \"serie\", \"series\", \"tv show\",\n",
    "          \"documental\", \"documentales\"\n",
    "      ]\n",
    "      if any(palabra in mensaje_lower for palabra in palabras_contenido):\n",
    "          return 'busqueda_contenido'\n",
    "\n",
    "      # PRIORIDAD 3: Palabras de b√∫squeda/recomendaci√≥n\n",
    "      indicadores_busqueda = [\n",
    "          \"recomienda\", \"recomendacion\", \"recomendaci√≥n\",\n",
    "          \"busco\", \"quiero ver\", \"dame\", \"muestra\",\n",
    "          \"sobre\", \"de\", \"acerca de\",\n",
    "          \"top\", \"mejores\", \"mejor\"\n",
    "      ]\n",
    "      if any(palabra in mensaje_lower for palabra in indicadores_busqueda):\n",
    "          return 'busqueda_contenido'\n",
    "\n",
    "      # PRIORIDAD 4: Detectar preguntas factuales\n",
    "      palabras_interrogativas = [\n",
    "          \"qui√©n\", \"quien\", \"qu√©\", \"que\",\n",
    "          \"cu√°ndo\", \"cuando\", \"d√≥nde\", \"donde\",\n",
    "          \"c√≥mo\", \"como\", \"por qu√©\", \"porque\",\n",
    "          \"cu√°l\", \"cual\"\n",
    "      ]\n",
    "\n",
    "      es_pregunta = (mensaje.strip().startswith(\"¬ø\") or mensaje.strip().startswith(\"?\") or\n",
    "                     any(palabra in mensaje_lower for palabra in palabras_interrogativas))\n",
    "\n",
    "      if es_pregunta:\n",
    "          # Verificar si menciona nombres de pel√≠culas/series/actores conocidos\n",
    "          # Si NO menciona contenido audiovisual ‚Üí es pregunta factual externa\n",
    "          palabras_cine = [\n",
    "              \"pel√≠cula\", \"pelicula\", \"serie\", \"film\", \"movie\",\n",
    "              \"actor\", \"actriz\", \"director\", \"personaje\",\n",
    "              \"temporada\", \"episodio\", \"estreno\", \"trama\"\n",
    "          ]\n",
    "          if not any(palabra in mensaje_lower for palabra in palabras_cine):\n",
    "              return 'pregunta_factual_externa'\n",
    "\n",
    "      return 'busqueda_contenido'\n",
    "\n",
    "print(\"Funci√≥n detectar_intencion creada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 36. Versi√≥n Mejorada del Agente con Historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funci√≥n chat_with_agent_gradio actualizada con l√≠mites din√°micos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  import gradio as gr\n",
    "\n",
    "  with gr.Blocks(theme=gr.themes.Soft(), title=\"CineBot\") as demo:\n",
    "\n",
    "      # Header\n",
    "      gr.Markdown(\n",
    "          \"\"\"\n",
    "          # üé¨ CineBot - Agente Recomendador Inteligente\n",
    "          ### Descubre pel√≠culas y series basadas en tus gustos\n",
    "          \"\"\"\n",
    "      )\n",
    "\n",
    "      with gr.Row():\n",
    "          # Columna principal: Chat\n",
    "          with gr.Column(scale=3):\n",
    "              chatbot = gr.Chatbot(\n",
    "                  label=\"Chat\",\n",
    "                  height=500,\n",
    "                  show_label=False\n",
    "              )\n",
    "\n",
    "              with gr.Row():\n",
    "                  msg = gr.Textbox(\n",
    "                      label=\"Escribe tu mensaje\",\n",
    "                      placeholder=\"Ej: Dame las mejores pel√≠culas de acci√≥n...\",\n",
    "                      scale=9,\n",
    "                      show_label=False\n",
    "                  )\n",
    "                  send_btn = gr.Button(\"üì§ Enviar\", scale=1, variant=\"primary\")\n",
    "\n",
    "              clear_btn = gr.Button(\"üóëÔ∏è Limpiar Chat\", size=\"sm\")\n",
    "\n",
    "          # Columna lateral: Informaci√≥n y ejemplos\n",
    "          with gr.Column(scale=1):\n",
    "              gr.Markdown(\"### üìä Base de Datos\")\n",
    "              gr.Markdown(\"17,344 t√≠tulos\\n\\nIMDB + Netflix\")\n",
    "\n",
    "              gr.Markdown(\"### üí° Ejemplos R√°pidos\")\n",
    "\n",
    "              example_btns = [\n",
    "                  gr.Button(\"üé≠ Top Dramas\", size=\"sm\"),\n",
    "                  gr.Button(\"üòÇ Comedias\", size=\"sm\"),\n",
    "                  gr.Button(\"üî™ Terror\", size=\"sm\"),\n",
    "                  gr.Button(\"‚ù§Ô∏è Romance\", size=\"sm\"),\n",
    "                  gr.Button(\"üöÄ Sci-Fi\", size=\"sm\"),\n",
    "              ]\n",
    "\n",
    "      # Footer\n",
    "      gr.Markdown(\n",
    "          \"\"\"\n",
    "          ---\n",
    "          üíª Powered by Claude AI | üé¨ Datos de IMDB & Netflix\n",
    "          \"\"\"\n",
    "      )\n",
    "\n",
    "      # Funci√≥n de respuesta\n",
    "      def respond(message, chat_history):\n",
    "          bot_message = chat_with_agent_gradio(message, chat_history)\n",
    "          chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "          chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "          return \"\", chat_history\n",
    "\n",
    "      # Eventos\n",
    "      msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "      send_btn.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "      clear_btn.click(lambda: [], None, chatbot)\n",
    "\n",
    "      # Botones de ejemplo\n",
    "      example_btns[0].click(lambda: \"Dame el top 5 de series de drama\", None, msg)\n",
    "      example_btns[1].click(lambda: \"Pel√≠culas de comedia divertidas\", None, msg)\n",
    "      example_btns[2].click(lambda: \"Las mejores pel√≠culas de terror\", None, msg)\n",
    "      example_btns[3].click(lambda: \"Series rom√°nticas\", None, msg)\n",
    "      example_btns[4].click(lambda: \"Pel√≠culas de ciencia ficci√≥n\", None, msg)\n",
    "\n",
    "  print(\"Interfaz Gradio avanzada creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 37. Interfaz Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interfaz Gradio con tema Netflix creada\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "                                                                                                                                                                                                # Tema Netflix personalizado\n",
    "netflix_theme = gr.themes.Soft(\n",
    "      primary_hue=\"red\",\n",
    "      secondary_hue=\"slate\",\n",
    "      neutral_hue=\"slate\",\n",
    "  ).set(\n",
    "      body_background_fill=\"#141414\",  # Negro Netflix\n",
    "      body_text_color=\"#ffffff\",\n",
    "      block_background_fill=\"#221f1f\",  # Gris oscuro Netflix\n",
    "      block_title_text_color=\"#ffffff\",\n",
    "      block_label_text_color=\"#ffffff\",\n",
    "      input_background_fill=\"#333333\",\n",
    "      button_primary_background_fill=\"#E50914\",  # Rojo Netflix\n",
    "      button_primary_background_fill_hover=\"#F40612\",  # Rojo m√°s brillante al hover\n",
    "      button_primary_text_color=\"#ffffff\",\n",
    "  )\n",
    "\n",
    "with gr.Blocks(theme=netflix_theme, title=\"CineBot\") as demo:\n",
    "\n",
    "      # Header\n",
    "      gr.Markdown(\n",
    "          \"\"\"\n",
    "          #  Agente Recomendador de Pel√≠culas y Series\n",
    "          ### Descubre pel√≠culas y series basadas en tus gustos\n",
    "          \"\"\"\n",
    "      )\n",
    "\n",
    "      with gr.Row():\n",
    "          with gr.Column(scale=3):\n",
    "              chatbot = gr.Chatbot(\n",
    "                  label=\"Chat\",\n",
    "                  height=500,\n",
    "                  show_label=False\n",
    "              )\n",
    "\n",
    "              with gr.Row():\n",
    "                  msg = gr.Textbox(\n",
    "                      label=\"Escribe tu mensaje\",\n",
    "                      placeholder=\"Ej: Dame las mejores pel√≠culas de acci√≥n...\",\n",
    "                      scale=9,\n",
    "                      show_label=False\n",
    "                  )\n",
    "                  send_btn = gr.Button(\"Enviar\", scale=1, variant=\"primary\")\n",
    "\n",
    "              clear_btn = gr.Button(\"Limpiar Chat\", size=\"sm\")\n",
    "\n",
    "          # Columna lateral: Informaci√≥n y ejemplos\n",
    "          with gr.Column(scale=1):\n",
    "              gr.Markdown(\"###  Base de Datos\")\n",
    "              gr.Markdown(\"**17,344 t√≠tulos**\\n\\nIMDB + Netflix\")\n",
    "\n",
    "              gr.Markdown(\"###  Ejemplos R√°pidos\")\n",
    "\n",
    "              example_btns = [\n",
    "                  gr.Button(\" Top Dramas\", size=\"sm\"),\n",
    "                  gr.Button(\" Comedias\", size=\"sm\"),\n",
    "                  gr.Button(\" Terror\", size=\"sm\"),\n",
    "                  gr.Button(\" Romance\", size=\"sm\"),\n",
    "                  gr.Button(\" Sci-Fi\", size=\"sm\"),\n",
    "              ]\n",
    "\n",
    "      # Footer\n",
    "      gr.Markdown(\n",
    "          \"\"\"\n",
    "          ---\n",
    "          Datos de IMDB & Netflix \n",
    "          \"\"\"\n",
    "      )\n",
    "\n",
    "      # Funci√≥n de respuesta\n",
    "      def respond(message, chat_history):\n",
    "          bot_message = chat_with_agent_gradio(message, chat_history)\n",
    "          chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "          chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "          return \"\", chat_history\n",
    "\n",
    "      # Eventos\n",
    "      msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "      send_btn.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "      clear_btn.click(lambda: [], None, chatbot)\n",
    "\n",
    "      # Botones de ejemplo\n",
    "      example_btns[0].click(lambda: \"Dame el top 5 de series de drama\", None, msg)\n",
    "      example_btns[1].click(lambda: \"Pel√≠culas de comedia divertidas\", None, msg)\n",
    "      example_btns[2].click(lambda: \"Las mejores pel√≠culas de terror\", None, msg)\n",
    "      example_btns[3].click(lambda: \"Series rom√°nticas\", None, msg)\n",
    "      example_btns[4].click(lambda: \"Pel√≠culas de ciencia ficci√≥n\", None, msg)\n",
    "\n",
    "print(\"Interfaz Gradio con tema Netflix creada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. Lanzar la Aplicaci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7895\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7895/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(\n",
    "      share=False,\n",
    "      server_name=\"127.0.0.1\",\n",
    "      server_port=7895,\n",
    "      show_error=True\n",
    "  )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
